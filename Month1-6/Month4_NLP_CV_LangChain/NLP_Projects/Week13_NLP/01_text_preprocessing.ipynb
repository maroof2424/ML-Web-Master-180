{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tSkprUJoS0Y2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEnVgZXlXwTu",
        "outputId": "4b6f791b-7df4-4265-bd0b-fe94333b3121"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing (NLP) helps computers understand human language. It's awesome!\"\n",
        "print(\"ðŸ”¹ Original Text:\\n\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Arm2_ExtZLQb",
        "outputId": "b500bc04-f8d6-4d15-a265-10299d37bdfc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Original Text:\n",
            " Natural Language Processing (NLP) helps computers understand human language. It's awesome!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_lower = text.lower()"
      ],
      "metadata": {
        "id": "8_2995obZPMK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clean = \"\".join([ch for ch in text_lower if ch not in string.punctuation])\n",
        "print(\"âœ… Cleaned Text:\\n\", text_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ik2EF29ZSo4",
        "outputId": "96fa6477-8ad7-460f-b50c-7626d7eaeac6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cleaned Text:\n",
            " natural language processing nlp helps computers understand human language its awesome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text_clean)\n",
        "print(\"ðŸ§© Tokens:\\n\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iueo_vGKZU6i",
        "outputId": "2f650b54-e79b-473a-82fd-7f24e5187cc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§© Tokens:\n",
            " ['natural', 'language', 'processing', 'nlp', 'helps', 'computers', 'understand', 'human', 'language', 'its', 'awesome']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [w for w in tokens if w not in stop_words]\n",
        "print(\"ðŸš« After Stopword Removal:\\n\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBBVm3e5ZYuI",
        "outputId": "4a8d3885-a452-4eea-b2e8-24188a5edb1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš« After Stopword Removal:\n",
            " ['natural', 'language', 'processing', 'nlp', 'helps', 'computers', 'understand', 'human', 'language', 'awesome']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"ðŸŒ± After Stemming:\\n\", stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0XXzYA0ZhfX",
        "outputId": "15d21e38-5fa8-4c67-d895-7d8a2643c1ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ± After Stemming:\n",
            " ['natur', 'languag', 'process', 'nlp', 'help', 'comput', 'understand', 'human', 'languag', 'awesom']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemm_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"ðŸ§  After Lemmatization:\\n\", lemm_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs_zkC4eZj_8",
        "outputId": "4e69f2ef-9035-4608-eeed-1c961d0e2945"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  After Lemmatization:\n",
            " ['natural', 'language', 'processing', 'nlp', 'help', 'computer', 'understand', 'human', 'language', 'awesome']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "Lv12T4M3ZmDq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"NLTK is a powerful Python library for text processing!\"\n",
        "print(\"âœ… Final Output:\", preprocess_text(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR1xQpxZZn2n",
        "outputId": "769835a4-4471-4f83-89b4-fe89623b60eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Final Output: ['nltk', 'powerful', 'python', 'library', 'text', 'processing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4MIppqeZpc3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}