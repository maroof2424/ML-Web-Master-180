

# âœ… Day 7 â€“ Review & Summary

## ðŸ“Œ What We Learned in Week 9:

### ðŸ”¹ Regression

* **Linear Regression** â†’ Continuous prediction (e.g., house price).
* **Metrics** â†’ MAE, RMSE, RÂ².

### ðŸ”¹ Logistic Regression

* **Binary classification** (0/1, Yes/No).
* Uses **Sigmoid function** for probabilities.

### ðŸ”¹ KNN

* Predicts based on **nearest neighbors**.
* **K** choice matters (too small â†’ noisy, too large â†’ underfit).

### ðŸ”¹ Decision Trees

* Splits data into **if/else rules**.
* Can be used for **both regression & classification**.

### ðŸ”¹ Evaluation Metrics

* **Regression:** MAE, RMSE.
* **Classification:** Accuracy, Confusion Matrix, Precision, Recall, F1.

### ðŸ”¹ Model Comparison

* Built **multiple models** and compared results.
* Learned that **no single model is best for all datasets**.

---

## ðŸŽ¯ Mini Task (Revision):

1. Load **Titanic dataset**.
2. Train **Logistic Regression, Decision Tree, Random Forest**.
3. Compare Accuracy & Confusion Matrix.

```python
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Load Titanic dataset
titanic = sns.load_dataset("titanic").dropna(subset=["age","fare","sex","class","survived"])
X = titanic[["age","fare"]]
X["sex"] = titanic["sex"].map({"male":0,"female":1})
y = titanic["survived"]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

# Models
models = {
    "Logistic Regression": LogisticRegression(max_iter=200),
    "Decision Tree": DecisionTreeClassifier(max_depth=5, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
}

# Train & Evaluate
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"\nðŸ”Ž {name}")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
```

--- 