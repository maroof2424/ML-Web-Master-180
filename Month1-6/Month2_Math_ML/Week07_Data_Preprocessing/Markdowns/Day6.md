# Week7 Day6
---

## ğŸ› ï¸ What is a **Pipeline** in ML?

ğŸ‘‰ A **Pipeline** in scikit-learn is a **sequence of steps** (like a factory assembly line) where **data flows through preprocessing â†’ feature transformation â†’ model training**.

Itâ€™s like a conveyor belt:

* Raw data goes in ğŸšª
* Each step (cleaning, scaling, encoding, model) happens in order âš™ï¸
* Final predictions come out ğŸ“Š

---

### ğŸ¯ Why use a Pipeline?

Without a pipeline:

* You separately **impute, scale, encode**, then train your model.
* You risk mistakes (e.g., forgetting to apply the same scaler on test data).
* Your code becomes messy.

With a pipeline:

* All steps are **chained together**.
* Training and test data go through the **exact same transformations**.
* You can **cross-validate** the *entire process* in one go.
* Makes deployment easy â†’ single object (`clf.predict(new_data)`).

---

### âš¡ Example Analogy

Imagine making **tea** ğŸµ:

1. Boil water
2. Add tea leaves
3. Add milk/sugar
4. Pour into cup

Each step must happen **in the right order**.
Thatâ€™s exactly how a pipeline works with data.

---

### âœ… In Code

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer

# Example: Pipeline for numeric features + model
pipeline = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),   # Handle missing values
    ("scaler", StandardScaler()),                    # Scale data
    ("classifier", LogisticRegression())             # Train model
])
```

Here:

1. Missing values â†’ filled
2. Data â†’ scaled
3. Logistic Regression â†’ trained

You can now call:

```python
pipeline.fit(X_train, y_train)  
pipeline.predict(X_test)  
```

---

### ğŸš€ What it *does*

* Ensures **consistency** between train/test preprocessing
* **Reduces boilerplate code**
* Supports **cross-validation & grid search** automatically
* Makes your workflow **production-ready**

---
